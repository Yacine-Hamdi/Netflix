{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0td7nj0wxgk"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des liens sur la page principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOO4kXMZxKxY"
   },
   "outputs": [],
   "source": [
    "url = \"https://freeglisse.com/fr/12-ski-occasion\"\n",
    "reponse = requests.get(url)\n",
    "html_content = reponse.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher une page\n",
    "def get_products():\n",
    "\tlinks_list = []\n",
    "\turl = 'https://freeglisse.com/fr/12-ski-occasion?page=1'\n",
    "\tresponse = requests.get(url)\n",
    "\tsoup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\th2_tags = soup.find_all('h2', class_ = 'h3 product-title')\n",
    "\tfor ski in h2_tags:\n",
    "\t\tproduct_links = [ski.a.get(\"href\") for ski in h2_tags]\n",
    "\tlinks_list.extend(product_links)\n",
    "\treturn links_list\n",
    "get_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08_Anh5ZxMR4"
   },
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    base_url = \"https://freeglisse.com/fr/12-ski-occasion/s-1/?page={}\"\n",
    "    current_page = 1\n",
    "\n",
    "    links_list = []\n",
    "\n",
    "    while True:\n",
    "        url = base_url.format(current_page)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Erreur lors de la requête HTTP\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        h2_tags = soup.find_all(\"h2\", {\"class\": \"h3 product-title\"})\n",
    "        product_links = [h2_tag.a.get(\"href\") for h2_tag in h2_tags]\n",
    "\n",
    "        links_list.extend(product_links)\n",
    "\n",
    "        next_page_link = soup.find(\"a\", {\"rel\": \"next\", \"class\": \"next js-search-link\"})\n",
    "        if not next_page_link:\n",
    "            break\n",
    "\n",
    "        current_page += 1\n",
    "\n",
    "    return links_list\n",
    "\n",
    "liste_lien = get_links()\n",
    "print(liste_lien)\n",
    "(len(liste_lien))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piq-RZT5wYTB"
   },
   "source": [
    "### Récupération des informations sur UNE page produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zEOZoT1rEPG"
   },
   "outputs": [],
   "source": [
    "#Test de récupération sur une page produit\n",
    "url_t = \"https://freeglisse.com/fr/ski-occasion-femme-loisir/18890-430528-ski-occasion-rossignol-nova-6-fixations.html#/3-etat_du_materiel-qualite_a/891-taille_skis-149_cm\"\n",
    "reponse_t = requests.get(url_t)\n",
    "html_content_t = reponse_t.text\n",
    "soup_t = BeautifulSoup(html_content_t, \"html.parser\")\n",
    "\n",
    "# pour obtenir la RÉFÉRENCE produit\n",
    "ref_produit = (soup_t.find(\"div\", {\"class\": \"product-reference rb-tag-cate\"}).text.strip()).replace(\"announcement Référence: \", \"\").strip()\n",
    "print(ref_produit)\n",
    "# pour obtenir le NOM du produit\n",
    "nom_produit = soup_t.find_all(\"h1\", {\"class\" : \"h1 product-detail-name\"})[0].get_text().strip()\n",
    "print(nom_produit)\n",
    "# pour obtenir la MARQUE du produit\n",
    "marque_produit = soup_t.find(\"img\", {\"class\" : \"img img-thumbnail manufacturer-logo\"}).get(\"alt\", \"\")\n",
    "print(marque_produit)\n",
    "# pour obtenir le PRIX du produit\n",
    "prix_produit = unidecode(soup_t.find_all(\"span\", {\"class\" : \"current-price-value\"})[0].get_text().strip())\n",
    "print(prix_produit)\n",
    "# pour obtenir le TYPE DE PRATIQUE du produit\n",
    "type_pratique = [soup_t.find_all(\"dd\", {\"class\" : \"value\"})[0].get_text().strip()]\n",
    "print(type_pratique)\n",
    "# pour obtenir le TYPE D'UTILISATEUR du produit\n",
    "utilisateur = [soup_t.find_all(\"dd\", {\"class\" : \"value\"})[1].get_text().strip()]\n",
    "print(utilisateur)\n",
    "# pour obtenir le NIVEAU du produit\n",
    "niveau = [soup_t.find_all(\"dd\", {\"class\" : \"value\"})[2].get_text().strip()]\n",
    "print(niveau)\n",
    "# pour obtenir la COULEUR du produit\n",
    "colori = [soup_t.find_all(\"dd\", {\"class\" : \"value\"})[3].get_text().strip()]\n",
    "print(colori)\n",
    "# pour obtenir le NOMBRE D'AVIS du produit\n",
    "nb_avis = soup_t.find(\"p\", {\"class\" : \"netreviews_subtitle\"}).find(\"span\", {\"id\": \"reviewCount\"}).text.strip()\n",
    "print(nb_avis)\n",
    "# pour obtenir la NOTE du produit\n",
    "note_produit = soup_t.find(\"p\", {\"class\" : \"netreviews_note_generale\"}).text.strip().split('/')[0]\n",
    "print(note_produit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITnKWa6W9qL3"
   },
   "source": [
    "#### Pour obtenir le nombre de produit disponible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialiser le driver (ajustez pour votre propre navigateur)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Ouvrir la page du produit\n",
    "driver.get(\"https://freeglisse.com/fr/ski-de-fond-occasion-alternatif-norme-sns/15483-167626-ski-de-fond-occasion-toutes-marques-fixation-vieux-sns.html#/882-taille_skis-140_cm/1768-etat_du_materiel-qualite_c\")\n",
    "\n",
    "# Attendre que la page soit complètement chargée\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Localiser le champ de quantité\n",
    "quantity_input = wait.until(EC.visibility_of_element_located((By.ID, \"quantity_wanted\")))\n",
    "\n",
    "# Variable pour stocker le maximum de produits en stock\n",
    "max_stock = 1  # Commencer avec une quantité de 1\n",
    "\n",
    "while True:\n",
    "    # Défiler pour que l'élément de quantité soit visible\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", quantity_input)\n",
    "    time.sleep(0.5)  # Petite pause pour s'assurer que l'élément est visible\n",
    "\n",
    "    # Utiliser JavaScript pour définir la valeur du champ de quantité\n",
    "    driver.execute_script(f\"arguments[0].value = {max_stock};\", quantity_input)\n",
    "    \n",
    "    # Simuler un événement 'change' sur le champ de quantité\n",
    "    driver.execute_script(\"var event = new Event('change', { bubbles: true }); arguments[0].dispatchEvent(event);\", quantity_input)\n",
    "    \n",
    "    # Attendre un peu pour que la page traite l'événement\n",
    "    time.sleep(2)  # Ajustez cette durée si nécessaire\n",
    "\n",
    "    # Rechercher le message de disponibilité à chaque itération\n",
    "    try:\n",
    "        # Localiser à nouveau le message de disponibilité\n",
    "        availability_message = wait.until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//span[@id='availability_message']\"))\n",
    "        )\n",
    "        availability_text = availability_message.text\n",
    "        print(f\"Message de disponibilité : {availability_text}\")\n",
    "\n",
    "        # Vérifier si le stock est suffisant\n",
    "        if \"pas assez\" in availability_text.lower():\n",
    "            print(f\"Stock maximum détecté avant l'erreur : {max_stock - 1}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la vérification du message : {str(e)}\")\n",
    "        break\n",
    "    \n",
    "    # Si le message est valide, augmenter la quantité\n",
    "    max_stock += 1\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pages(base_url):\n",
    "    urls = []\n",
    "    current_page = 1\n",
    "    \n",
    "    while True:\n",
    "        full_url = f\"{base_url}{current_page}\"\n",
    "        response = requests.get(full_url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        urls.append(full_url)\n",
    "        \n",
    "        next_page_link = soup.find(\"a\", {\"rel\": \"next\", \"class\": \"next js-search-link\"})\n",
    "        if not next_page_link:\n",
    "            break\n",
    "        \n",
    "        current_page += 1\n",
    "    \n",
    "    return urls\n",
    "\n",
    "qualiteA = get_all_pages('https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_a?page=')\n",
    "qualiteB = get_all_pages('https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_b?page=')\n",
    "qualiteC = get_all_pages('https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_c?page=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualiteA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i72DareWaoat"
   },
   "source": [
    "### Obtention de tous les liens disponibles sur le site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de récupérer tous les liens des skis, nous allons faire une boucle par qualité (A,B et C). Il fautdrai également obtenir les liens en fonction des tailles (ce qui n'est pas encore fait ici)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table qualité A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TR6OERnmauyh"
   },
   "outputs": [],
   "source": [
    "url_a = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_a\"\n",
    "reponse_a = requests.get(url_a)\n",
    "html_content_a = reponse_a.text\n",
    "soup_a = BeautifulSoup(html_content_a, \"html.parser\")\n",
    "\n",
    "def table_qualite_a():\n",
    "\tbase_url = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_a?page={}&order=product.price.desc\"\n",
    "\tcurrent_page = 1\n",
    "\n",
    "\tdf_global_a = pd.DataFrame(columns=['nom', 'prix', 'lien'])\n",
    "\n",
    "\twhile True:\n",
    "\t\turl = base_url.format(current_page)\n",
    "\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tif response.status_code != 200:\n",
    "\t\t\tprint(\"Erreur lors de la requête HTTP\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\t\tbalises_h2 = soup.find_all(\"h2\", {\"class\": \"h3 product-title\"})\n",
    "\t\tnoms_produits = [balise_h2.a.text.strip() for balise_h2 in balises_h2]\n",
    "\n",
    "\t\tprices = [unidecode(span.get_text().strip()) for span in soup.find_all(\"span\", {\"class\": \"price\"})]\n",
    "\n",
    "\t\tproduct_links = [h2_tag.a.get(\"href\") for h2_tag in balises_h2]\n",
    "\n",
    "\t\tdata = {'nom': noms_produits, 'prix': prices, 'lien': product_links}\n",
    "\t\tdf_current = pd.DataFrame(data)\n",
    "\n",
    "\t\tdf_global_a = pd.concat([df_global_a, df_current], ignore_index=True)\n",
    "\n",
    "\t\tnext_page_link = soup.find(\"a\", {\"rel\": \"next\", \"class\": \"next js-search-link\"})\n",
    "\t\tif not next_page_link:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcurrent_page += 1\n",
    "\treturn df_global_a\n",
    "\n",
    "df_a = table_qualite_a()\n",
    "\n",
    "df_a['Qualité'] = 'Qualité A'\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D9QORiybI5d"
   },
   "source": [
    "#### Table qualité B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHfbpB4jbQft"
   },
   "outputs": [],
   "source": [
    "url_b = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_b\"\n",
    "reponse_b = requests.get(url_b)\n",
    "html_content_b = reponse_b.text\n",
    "soup_b = BeautifulSoup(html_content_b, \"html.parser\")\n",
    "\n",
    "def table_qualite_b():\n",
    "\tbase_url = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_b?page={}&order=product.price.desc\"\n",
    "\tcurrent_page = 1\n",
    "\n",
    "\tdf_global_b = pd.DataFrame(columns=['nom', 'prix', 'lien'])\n",
    "\n",
    "\twhile True:\n",
    "\t\turl = base_url.format(current_page)\n",
    "\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tif response.status_code != 200:\n",
    "\t\t\tprint(\"Erreur lors de la requête HTTP\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\t\tbalises_h2 = soup.find_all(\"h2\", {\"class\": \"h3 product-title\"})\n",
    "\t\tnoms_produits = [balise_h2.a.text.strip() for balise_h2 in balises_h2]\n",
    "\n",
    "\t\tprices = [unidecode(span.get_text().strip()) for span in soup.find_all(\"span\", {\"class\": \"price\"})]\n",
    "\n",
    "\t\tproduct_links = [h2_tag.a.get(\"href\") for h2_tag in balises_h2]\n",
    "\n",
    "\t\tdata = {'nom': noms_produits, 'prix': prices, 'lien': product_links}\n",
    "\t\tdf_current = pd.DataFrame(data)\n",
    "\n",
    "\t\tdf_global_b = pd.concat([df_global_b, df_current], ignore_index=True)\n",
    "\n",
    "\t\tnext_page_link = soup.find(\"a\", {\"rel\": \"next\", \"class\": \"next js-search-link\"})\n",
    "\t\tif not next_page_link:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcurrent_page += 1\n",
    "\treturn df_global_b\n",
    "\n",
    "df_b = table_qualite_b()\n",
    "\n",
    "df_b['Qualité'] = 'Qualité B'\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Mj6MUfbb-5"
   },
   "source": [
    "#### Table qualité C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfSUdVhgbewb"
   },
   "outputs": [],
   "source": [
    "url_c = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_c\"\n",
    "reponse_c = requests.get(url_c)\n",
    "html_content_c = reponse_c.text\n",
    "soup_c = BeautifulSoup(html_content_c, \"html.parser\")\n",
    "\n",
    "def table_qualite_c():\n",
    "\tbase_url = \"https://freeglisse.com/fr/12-ski-occasion/s-1/etat_du_materiel-qualite_c?page={}&order=product.price.desc\"\n",
    "\tcurrent_page = 1\n",
    "\n",
    "\tdf_global_c = pd.DataFrame(columns=['nom', 'prix', 'lien'])\n",
    "\n",
    "\twhile True:\n",
    "\t\turl = base_url.format(current_page)\n",
    "\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tif response.status_code != 200:\n",
    "\t\t\tprint(\"Erreur lors de la requête HTTP\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\t\tbalises_h2 = soup.find_all(\"h2\", {\"class\": \"h3 product-title\"})\n",
    "\t\tnoms_produits = [balise_h2.a.text.strip() for balise_h2 in balises_h2]\n",
    "\n",
    "\t\tprices = [unidecode(span.get_text().strip()) for span in soup.find_all(\"span\", {\"class\": \"price\"})]\n",
    "\n",
    "\t\tproduct_links = [h2_tag.a.get(\"href\") for h2_tag in balises_h2]\n",
    "\n",
    "\t\tdata = {'nom': noms_produits, 'prix': prices, 'lien': product_links}\n",
    "\t\tdf_current = pd.DataFrame(data)\n",
    "\n",
    "\t\tdf_global_c = pd.concat([df_global_c, df_current], ignore_index=True)\n",
    "\n",
    "\t\tnext_page_link = soup.find(\"a\", {\"rel\": \"next\", \"class\": \"next js-search-link\"})\n",
    "\t\tif not next_page_link:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcurrent_page += 1\n",
    "\treturn df_global_c\n",
    "\n",
    "df_c = table_qualite_c()\n",
    "\n",
    "df_c['Qualité'] = 'Qualité C'\n",
    "df_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q6Y75owbx78"
   },
   "source": [
    "#### MERGE A,B et C pour All_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "DG2l_VDfb2Ge",
    "outputId": "137bf280-f921-4698-8a7d-6ad2f46fef7c"
   },
   "outputs": [],
   "source": [
    "frames = [df_a, df_b, df_c]\n",
    "all_df = pd.concat(frames)\n",
    "display(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.groupby(['lien', 'Qualité']).count().reset_index().sort_values(by='nom', ascending=False).drop_duplicates(subset=['lien']).value_counts('Qualité')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle V1 (SANS les stocks) pour obtenir toutes les informations sur toutes les pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOga6gGQABhj"
   },
   "outputs": [],
   "source": [
    "def TOUFIK():\n",
    "\n",
    "    # CREATION DES LISTES\n",
    "    nom_produit_list = []\n",
    "    marque_produit_list = []\n",
    "    prix_produit_list = []\n",
    "    ref_produit_list = []\n",
    "    type_pratique_list = []\n",
    "    utilisateur_list = []\n",
    "    niveau_list = []\n",
    "    colori_list = []\n",
    "    nb_avis_list = []\n",
    "    note_produit_list = []\n",
    "    availability_msg_list = []\n",
    "\n",
    "    for link in all_df['lien']:\n",
    "        url_p = link\n",
    "        reponse_p = requests.get(url_p)\n",
    "        html_content_p = reponse_p.text\n",
    "        soup_p = BeautifulSoup(html_content_p, \"html.parser\")\n",
    "\n",
    "        # PART 2 - récupérer les infos de la page produit\n",
    "        # Le NOM du produit\n",
    "        nom_produit = soup_p.find_all(\"h1\", {\"class\": \"h1 product-detail-name\"})\n",
    "        nom_produit_list.append(nom_produit[0].get_text().strip() if nom_produit else np.nan)\n",
    "\n",
    "        # La MARQUE du produit\n",
    "        marque_produit = soup_p.find(\"img\", {\"class\": \"img img-thumbnail manufacturer-logo\"})\n",
    "        marque_produit_list.append(marque_produit.get(\"alt\", \"\") if marque_produit else np.nan)\n",
    "\n",
    "        # Le PRIX du produit\n",
    "        prix_produit = soup_p.find_all(\"span\", {\"class\": \"current-price-value\"})\n",
    "        prix_produit_list.append(unidecode(prix_produit[0].get_text().strip()) if prix_produit else np.nan)\n",
    "\n",
    "        # La REF du produit\n",
    "        ref_produit = soup_p.find(\"div\", {\"class\": \"product-reference rb-tag-cate\"})\n",
    "        ref_produit_list.append(\n",
    "            (ref_produit.text.strip().replace(\"announcement Référence: \", \"\").strip()) if ref_produit else np.nan)\n",
    "\n",
    "        # La DESCRIPTION du produit\n",
    "        descrip_prod_1 = soup_p.find_all(\"dd\", {\"class\": \"value\"})\n",
    "        type_pratique_list.append(descrip_prod_1[0].get_text().strip() if descrip_prod_1 else 'Null')\n",
    "        utilisateur_list.append(descrip_prod_1[1].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 1 else np.nan)\n",
    "        niveau_list.append(descrip_prod_1[2].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 2 else np.nan)\n",
    "        colori_list .append(descrip_prod_1[3].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 3 else np.nan)\n",
    "\n",
    "        #Le NB d'avis\n",
    "        nb_avis_element = soup_p.find(\"p\", {\"class\": \"netreviews_subtitle\"})\n",
    "        nb_avis = nb_avis_element.find(\"span\", {\"id\": \"reviewCount\"}).text.strip() if nb_avis_element else np.nan\n",
    "        nb_avis_list.append(nb_avis)\n",
    "\n",
    "        # La NOTE du 5\n",
    "        note_produit_element = soup_p.find(\"p\", {\"class\": \"netreviews_note_generale\"})\n",
    "        note_produit = note_produit_element.text.strip().split('/')[0] if note_produit_element else np.nan\n",
    "        note_produit_list.append(note_produit)\n",
    "\n",
    "        # La DISPONIBILITÉ du produit\n",
    "        availability_msg = soup_p.find('span', {'id': 'availability_message'})\n",
    "        availability_msg_list.append(availability_msg.get_text().strip() if availability_msg else np.nan)\n",
    "\n",
    "    # APPEND AUX LISTES\n",
    "    all_df['nom_produit'] = nom_produit_list\n",
    "    all_df['marque_produit'] = marque_produit_list\n",
    "    all_df['prix_produit'] = prix_produit_list\n",
    "    all_df['ref_produit'] = ref_produit_list\n",
    "    all_df['type_pratique'] = type_pratique_list\n",
    "    all_df['utilisateur'] = utilisateur_list\n",
    "    all_df['niveau'] = niveau_list\n",
    "    all_df['colori'] = colori_list\n",
    "    all_df['nb_avis'] = nb_avis_list\n",
    "    all_df['note_produit'] = note_produit_list\n",
    "    all_df['availability_msg'] = availability_msg_list\n",
    "    \n",
    "TOUFIK()\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mO0SfQQNHYcP",
    "outputId": "89fd5918-b28b-4685-9cab-f9e0e98bfa90"
   },
   "outputs": [],
   "source": [
    "#CheakPoint\n",
    "all_df.to_csv('/Users/yacinehamdi/Downloads/freegliss.csv')\n",
    "#df = pd.read_csv(\"/Users/yacinehamdi/Downloads/freegliss.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle V2 (AVEC les stocks) pour obtenir toutes les informations sur toutes les pages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette boucle peut-être très longue (environ 50 heures pour 2000 articles)\n",
    "Nous allons donc tester sur les 10 premiers articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sur 10 articles\n",
    "test = df_a.sample(10)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TOUFIK():\n",
    "    # CREATION DES LISTES\n",
    "    nom_produit_list = []\n",
    "    marque_produit_list = []\n",
    "    prix_produit_list = []\n",
    "    ref_produit_list = []\n",
    "    type_pratique_list = []\n",
    "    utilisateur_list = []\n",
    "    niveau_list = []\n",
    "    colori_list = []\n",
    "    nb_avis_list = []\n",
    "    note_produit_list = []\n",
    "    availability_msg_list = []\n",
    "    stock_list = []  # Liste pour le stock\n",
    "\n",
    "    # Initialiser le WebDriver (spécifiez le chemin vers le chromedriver si nécessaire)\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for link in test['lien']:\n",
    "        url_p = link\n",
    "        reponse_p = requests.get(url_p)\n",
    "        html_content_p = reponse_p.text\n",
    "        soup_p = BeautifulSoup(html_content_p, \"html.parser\")\n",
    "\n",
    "        # PART 2 - récupérer les infos de la page produit\n",
    "        # Le NOM du produit\n",
    "        nom_produit = soup_p.find_all(\"h1\", {\"class\": \"h1 product-detail-name\"})\n",
    "        nom_produit_list.append(nom_produit[0].get_text().strip() if nom_produit else np.nan)\n",
    "\n",
    "        # La MARQUE du produit\n",
    "        marque_produit = soup_p.find(\"img\", {\"class\": \"img img-thumbnail manufacturer-logo\"})\n",
    "        marque_produit_list.append(marque_produit.get(\"alt\", \"\") if marque_produit else np.nan)\n",
    "\n",
    "        # Le PRIX du produit\n",
    "        prix_produit = soup_p.find_all(\"span\", {\"class\": \"current-price-value\"})\n",
    "        prix_produit_list.append(unidecode(prix_produit[0].get_text().strip()) if prix_produit else np.nan)\n",
    "\n",
    "        # La REF du produit\n",
    "        ref_produit = soup_p.find(\"div\", {\"class\": \"product-reference rb-tag-cate\"})\n",
    "        ref_produit_list.append(\n",
    "            (ref_produit.text.strip().replace(\"announcement Référence: \", \"\").strip()) if ref_produit else np.nan)\n",
    "\n",
    "        # La DESCRIPTION du produit\n",
    "        descrip_prod_1 = soup_p.find_all(\"dd\", {\"class\": \"value\"})\n",
    "        type_pratique_list.append(descrip_prod_1[0].get_text().strip() if descrip_prod_1 else 'Null')\n",
    "        utilisateur_list.append(descrip_prod_1[1].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 1 else np.nan)\n",
    "        niveau_list.append(descrip_prod_1[2].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 2 else np.nan)\n",
    "        colori_list.append(descrip_prod_1[3].get_text().strip() if descrip_prod_1 and len(descrip_prod_1) > 3 else np.nan)\n",
    "\n",
    "        # Le NB d'avis\n",
    "        nb_avis_element = soup_p.find(\"p\", {\"class\": \"netreviews_subtitle\"})\n",
    "        nb_avis = nb_avis_element.find(\"span\", {\"id\": \"reviewCount\"}).text.strip() if nb_avis_element else np.nan\n",
    "        nb_avis_list.append(nb_avis)\n",
    "\n",
    "        # La NOTE du produit\n",
    "        note_produit_element = soup_p.find(\"p\", {\"class\": \"netreviews_note_generale\"})\n",
    "        note_produit = note_produit_element.text.strip().split('/')[0] if note_produit_element else np.nan\n",
    "        note_produit_list.append(note_produit)\n",
    "\n",
    "        # Ouvrir la page avec Selenium pour récupérer le stock\n",
    "        driver.get(url_p)\n",
    "\n",
    "        # Attendre que la page soit complètement chargée\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Variable pour stocker le maximum de produits en stock\n",
    "        max_stock = 1  # Commencer avec une quantité de 1\n",
    "        stock_found = False  # Variable pour détecter si le stock est trouvé\n",
    "\n",
    "        try:\n",
    "            # Localiser le champ de quantité\n",
    "            quantity_input = wait.until(EC.visibility_of_element_located((By.ID, \"quantity_wanted\")))\n",
    "\n",
    "            while True:\n",
    "                # Utiliser JavaScript pour définir la valeur du champ de quantité\n",
    "                driver.execute_script(f\"arguments[0].value = {max_stock};\", quantity_input)\n",
    "                \n",
    "                # Simuler un événement 'change' sur le champ de quantité\n",
    "                driver.execute_script(\"var event = new Event('change', { bubbles: true }); arguments[0].dispatchEvent(event);\", quantity_input)\n",
    "                        # Faire défiler vers le haut de la page\n",
    "                driver.execute_script(\"window.scrollTo(1, 1);\")\n",
    "                time.sleep(1)  # Petite pause pour s'assurer que le scroll est terminé\n",
    "                # Attendre un peu pour que la page traite l'événement\n",
    "                time.sleep(2)  # Ajustez cette durée si nécessaire\n",
    "                # Rechercher le message de disponibilité à chaque itération\n",
    "                try:\n",
    "                    # Localiser à nouveau le message de disponibilité\n",
    "                    availability_message = wait.until(\n",
    "                        EC.visibility_of_element_located((By.XPATH, \"//span[@id='availability_message']\"))\n",
    "                    )\n",
    "                    availability_text = availability_message.text\n",
    "                    print(f\"Message de disponibilité : {availability_text}\")\n",
    "\n",
    "                    # Vérifier si le stock est insuffisant\n",
    "                    if \"pas assez\" in availability_text.lower():\n",
    "                        stock_list.append(max_stock - 1)\n",
    "                        stock_found = True\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la vérification du message : {str(e)}\")\n",
    "                    break\n",
    "                \n",
    "                # Si le message est valide, augmenter la quantité\n",
    "                max_stock += 1\n",
    "\n",
    "                # Défiler pour que l'élément de quantité soit visible\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", quantity_input)\n",
    "                time.sleep(0.5)  # Petite pause pour s'assurer que l'élément est visible\n",
    "\n",
    "            # Si aucun stock n'est trouvé, ajouter np.nan\n",
    "            if not stock_found:\n",
    "                stock_list.append(np.nan)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la vérification du stock : {e}\")\n",
    "            stock_list.append(np.nan)  # En cas d'erreur, on ajoute np.nan\n",
    "\n",
    "    # APPEND AUX LISTES\n",
    "    test['nom_produit'] = nom_produit_list\n",
    "    test['marque_produit'] = marque_produit_list\n",
    "    test['prix_produit'] = prix_produit_list\n",
    "    test['ref_produit'] = ref_produit_list\n",
    "    test['type_pratique'] = type_pratique_list\n",
    "    test['utilisateur'] = utilisateur_list\n",
    "    test['niveau'] = niveau_list\n",
    "    test['colori'] = colori_list\n",
    "    test['nb_avis'] = nb_avis_list\n",
    "    test['note_produit'] = note_produit_list\n",
    "    #test['availability_msg'] = availability_msg_list\n",
    "    test['stock'] = stock_list  # Ajout des stocks à la DataFrame\n",
    "\n",
    "    # Fermer le WebDriver à la fin\n",
    "    driver.quit()\n",
    "\n",
    "TOUFIK()\n",
    "display(test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
